services:
  - type: web
    name: llm-visualizer
    env: python
    region: oregon
    plan: free
    buildCommand: "./build.sh"
    startCommand: "gunicorn llm_visualizer.wsgi:application"
    envVars:
      - key: PYTHON_VERSION
        value: 3.11.0
      - key: SECRET_KEY
        generateValue: true
      - key: DEBUG
        value: False
      - key: ALLOWED_HOSTS
        sync: false
      - key: DATABASE_URL
        fromDatabase:
          name: llm-visualizer-db
          property: connectionString
      - key: REDIS_URL
        fromService:
          type: redis
          name: llm-visualizer-redis
          property: connectionString
      - key: OLLAMA_BASE_URL
        value: http://localhost:11434
      - key: OLLAMA_DEFAULT_MODEL
        value: llama3.2

databases:
  - name: llm-visualizer-db
    plan: free
    databaseName: llm_visualizer
    user: llm_visualizer

# Note: Redis is optional - only needed for Celery background tasks
# services:
#   - type: redis
#     name: llm-visualizer-redis
#     plan: free
